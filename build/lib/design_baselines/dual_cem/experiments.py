from ray import tune
import click
import ray
import os


@click.group()
def cli():
    """A group of experiments for training Conservative Score Models
    and reproducing our ICLR 2021 results.
    """


@cli.command()
def test():
    from design_baselines.dual_cem import dual_cem
    config={
            "logging_dir": "test",
            "is_discrete": False,
            "normalize_ys": True,
            "normalize_xs": True,
            "task": "Superconductor-v0",
            "task_kwargs": {"split_percentile": 80},
            "bootstraps": 5,
            "val_size": 200,
            "ensemble_batch_size": 100,
            "vae_batch_size": 100,
            "hidden_size": 256,
            "initial_max_std": 0.2,
            "initial_min_std": 0.1,
            "ensemble_lr": 0.001,
            "ensemble_epochs": 100,
            "latent_size": 32,
            "vae_lr": 0.001,
            "vae_beta": 20.0,
            "offline_epochs": 200,
            "online_batches": 100,
            "online_epochs": 1,
            "iterations": 200,
            "alpha": 1.0,
            "gamma_percentile": 1.0,
            "solver_samples": 128,
        }
    dual_cem(config)

#############


@cli.command()
@click.option("--local-dir", type=str, default="dual-cem-dkitty")
@click.option("--cpus", type=int, default=24)
@click.option("--gpus", type=int, default=1)
@click.option("--num-parallel", type=int, default=1)
@click.option("--num-samples", type=int, default=1)
def dkitty(local_dir, cpus, gpus, num_parallel, num_samples):
    """Evaluate CbAS on DKittyMorphology-v0
    """

    # Final Version

    from design_baselines.dual_cem import dual_cem

    ray.init(num_cpus=cpus, num_gpus=gpus, temp_dir=os.path.expanduser("~/tmp"))
    tune.run(
        dual_cem,
        config={
            "logging_dir": "data",
            "is_discrete": False,
            "normalize_ys": True,
            "normalize_xs": True,
            "task": "DKittyMorphology-v0",
            "task_kwargs": {"split_percentile": 40, "num_parallel": 2},
            "bootstraps": 5,
            "val_size": 200,
            "ensemble_batch_size": 100,
            "vae_batch_size": 100,
            "hidden_size": 256,
            "initial_max_std": 0.2,
            "initial_min_std": 0.1,
            "ensemble_lr": 0.001,
            "ensemble_epochs": 100,
            "latent_size": 32,
            "vae_lr": 0.0005,
            "vae_beta": 2.0,
            "offline_epochs": 200,
            "online_batches": 10,
            "online_epochs": 10,
            "iterations": 50,
            "percentile": 80.0,
            "solver_samples": 128,
        },
        num_samples=num_samples,
        local_dir=local_dir,
        resources_per_trial={"cpu": cpus // num_parallel, "gpu": gpus / num_parallel - 0.01},
    )


@cli.command()
@click.option("--local-dir", type=str, default="dual-cem-ant")
@click.option("--cpus", type=int, default=24)
@click.option("--gpus", type=int, default=1)
@click.option("--num-parallel", type=int, default=1)
@click.option("--num-samples", type=int, default=1)
def ant(local_dir, cpus, gpus, num_parallel, num_samples):
    """Evaluate CbAS on AntMorphology-v0
    """

    # Final Version

    from design_baselines.dual_cem import dual_cem

    ray.init(num_cpus=cpus, num_gpus=gpus, temp_dir=os.path.expanduser("~/tmp"))
    tune.run(
        dual_cem,
        config={
            "logging_dir": "data",
            "is_discrete": False,
            "normalize_ys": True,
            "normalize_xs": True,
            "task": "AntMorphology-v0",
            "task_kwargs": {"split_percentile": 20, "num_parallel": 2},
            "bootstraps": 5,
            "val_size": 200,
            "ensemble_batch_size": 100,
            "vae_batch_size": 100,
            "hidden_size": 256,
            "initial_max_std": 0.2,
            "initial_min_std": 0.1,
            "ensemble_lr": 0.001,
            "ensemble_epochs": 100,
            "latent_size": 32,
            "vae_lr": 0.001,
            "vae_beta": 2.0,
            "offline_epochs": 200,
            "online_batches": 10,
            "online_epochs": 10,
            "iterations": 50,
            "percentile": 80.0,
            "solver_samples": 128,
        },
        num_samples=num_samples,
        local_dir=local_dir,
        resources_per_trial={"cpu": cpus // num_parallel, "gpu": gpus / num_parallel - 0.01},
    )


@cli.command()
@click.option("--local-dir", type=str, default="dual-cem-hopper")
@click.option("--cpus", type=int, default=24)
@click.option("--gpus", type=int, default=1)
@click.option("--num-parallel", type=int, default=1)
@click.option("--num-samples", type=int, default=1)
def hopper(local_dir, cpus, gpus, num_parallel, num_samples):
    """Evaluate CbAS on HopperController-v0
    """

    # Final Version

    from design_baselines.dual_cem import dual_cem

    ray.init(num_cpus=cpus, num_gpus=gpus, temp_dir=os.path.expanduser("~/tmp"))
    tune.run(
        dual_cem,
        config={
            "logging_dir": "data",
            "is_discrete": False,
            "normalize_ys": True,
            "normalize_xs": True,
            "task": "HopperController-v0",
            "task_kwargs": {},
            "bootstraps": 5,
            "val_size": 200,
            "ensemble_batch_size": 100,
            "vae_batch_size": 100,
            "hidden_size": 256,
            "initial_max_std": 0.2,
            "initial_min_std": 0.1,
            "ensemble_lr": 0.001,
            "ensemble_epochs": 100,
            "latent_size": 32,
            "vae_lr": 0.001,
            "vae_beta": 200.0,
            "offline_epochs": 200,
            "online_batches": 10,
            "online_epochs": 10,
            "iterations": 50,
            "percentile": 80.0,
            "solver_samples": 128,
        },
        num_samples=num_samples,
        local_dir=local_dir,
        resources_per_trial={"cpu": cpus // num_parallel, "gpu": gpus / num_parallel - 0.01},
    )


@cli.command()
@click.option("--local-dir", type=str, default="dual-cem-superconductor")
@click.option("--cpus", type=int, default=24)
@click.option("--gpus", type=int, default=1)
@click.option("--num-parallel", type=int, default=1)
@click.option("--num-samples", type=int, default=1)
def superconductor(local_dir, cpus, gpus, num_parallel, num_samples):
    """Evaluate CbAS on Superconductor-v0
    """

    # Final Version

    from design_baselines.dual_cem import dual_cem

    ray.init(num_cpus=cpus, num_gpus=gpus, temp_dir=os.path.expanduser("~/tmp"))
    tune.run(
        dual_cem,
        config={
            "logging_dir": "data",
            "is_discrete": False,
            "normalize_ys": True,
            "normalize_xs": True,
            "task": "Superconductor-v0",
            "task_kwargs": {"split_percentile": 80},
            "bootstraps": 5,
            "val_size": 200,
            "ensemble_batch_size": 100,
            "vae_batch_size": 100,
            "hidden_size": 256,
            "initial_max_std": 0.2,
            "initial_min_std": 0.1,
            "ensemble_lr": 0.001,
            "ensemble_epochs": 100,
            "latent_size": 32,
            "vae_lr": 0.001,
            "vae_beta": 20.0,
            "offline_epochs": 200,
            "online_batches": 100,
            "online_epochs": 1,
            "iterations": 200,
            "alpha": 1.0,
            "gamma_percentile": 1.0,
            "solver_samples": 128,
        },
        num_samples=num_samples,
        local_dir=local_dir,
        resources_per_trial={"cpu": cpus // num_parallel, "gpu": gpus / num_parallel - 0.01},
    )


@cli.command()
@click.option("--local-dir", type=str, default="dual-cem-molecule")
@click.option("--cpus", type=int, default=24)
@click.option("--gpus", type=int, default=1)
@click.option("--num-parallel", type=int, default=1)
@click.option("--num-samples", type=int, default=1)
def molecule(local_dir, cpus, gpus, num_parallel, num_samples):
    """Evaluate CbAS on MoleculeActivity-v0
    """

    # Final Version

    from design_baselines.dual_cem import dual_cem

    ray.init(num_cpus=cpus, num_gpus=gpus, temp_dir=os.path.expanduser("~/tmp"))
    tune.run(
        dual_cem,
        config={
            "logging_dir": "data",
            "is_discrete": True,
            "normalize_ys": True,
            "normalize_xs": False,
            "task": "MoleculeActivity-v0",
            "task_kwargs": {"split_percentile": 80},
            "bootstraps": 5,
            "val_size": 200,
            "ensemble_batch_size": 100,
            "vae_batch_size": 100,
            "hidden_size": 256,
            "initial_max_std": 0.2,
            "initial_min_std": 0.1,
            "ensemble_lr": 0.001,
            "ensemble_epochs": 100,
            "latent_size": 32,
            "vae_lr": 0.001,
            "vae_beta": 10.0,
            "offline_epochs": 200,
            "online_batches": 100,
            "online_epochs": 1,
            "iterations": 50,
            "alpha": 1.0,
            "gamma_percentile": 1.0,
            "solver_samples": 128,
        },
        num_samples=num_samples,
        local_dir=local_dir,
        resources_per_trial={"cpu": cpus // num_parallel, "gpu": gpus / num_parallel - 0.01},
    )


@cli.command()
@click.option("--local-dir", type=str, default="dual-cem-gfp")
@click.option("--cpus", type=int, default=24)
@click.option("--gpus", type=int, default=1)
@click.option("--num-parallel", type=int, default=1)
@click.option("--num-samples", type=int, default=1)
def gfp(local_dir, cpus, gpus, num_parallel, num_samples):
    """Evaluate CbAS on GFP-v0
    """

    # Final Version

    from design_baselines.dual_cem import dual_cem

    ray.init(num_cpus=cpus, num_gpus=gpus, temp_dir=os.path.expanduser("~/tmp"))
    tune.run(
        dual_cem,
        config={
            "logging_dir": "data",
            "is_discrete": True,
            "normalize_ys": True,
            "normalize_xs": False,
            "task": "GFP-v0",
            "task_kwargs": {"seed": tune.randint(1000)},
            "bootstraps": 5,
            "val_size": 200,
            "ensemble_batch_size": 100,
            "vae_batch_size": 100,
            "hidden_size": 256,
            "initial_max_std": 0.2,
            "initial_min_std": 0.1,
            "ensemble_lr": 0.001,
            "ensemble_epochs": 100,
            "latent_size": 32,
            "vae_lr": 0.001,
            "vae_beta": 5.0,
            "offline_epochs": 200,
            "online_batches": 100,
            "online_epochs": 1,
            "iterations": 50,
            "alpha": 1.0,
            "gamma_percentile": 1.0,
            "solver_samples": 128,
        },
        num_samples=num_samples,
        local_dir=local_dir,
        resources_per_trial={"cpu": cpus // num_parallel, "gpu": gpus / num_parallel - 0.01},
    )


@cli.command()
@click.option("--local-dir", type=str, default="dual-cem-gfp-v1")
@click.option("--cpus", type=int, default=24)
@click.option("--gpus", type=int, default=1)
@click.option("--num-parallel", type=int, default=1)
@click.option("--num-samples", type=int, default=1)
def gfp_v1(local_dir, cpus, gpus, num_parallel, num_samples):
    """Evaluate CbAS on GFP-v1
    """

    # Final Version

    from design_baselines.dual_cem import dual_cem

    ray.init(num_cpus=cpus, num_gpus=gpus, temp_dir=os.path.expanduser("~/tmp"))
    tune.run(
        dual_cem,
        config={
            "logging_dir": "data",
            "is_discrete": True,
            "normalize_ys": True,
            "normalize_xs": False,
            "task": "GFP-v1",
            "task_kwargs": {"split_percentile": 20},
            "bootstraps": 5,
            "val_size": 200,
            "ensemble_batch_size": 100,
            "vae_batch_size": 100,
            "hidden_size": 256,
            "initial_max_std": 0.2,
            "initial_min_std": 0.1,
            "ensemble_lr": 0.001,
            "ensemble_epochs": 100,
            "latent_size": 32,
            "vae_lr": 0.001,
            "vae_beta": 5.0,
            "offline_epochs": 200,
            "online_batches": 100,
            "online_epochs": 1,
            "iterations": 50,
            "alpha": 1.0,
            "gamma_percentile": 1.0,
            "solver_samples": 128,
        },
        num_samples=num_samples,
        local_dir=local_dir,
        resources_per_trial={"cpu": cpus // num_parallel, "gpu": gpus / num_parallel - 0.01},
    )
